{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "736b290b-77b2-4915-86a4-9745a3eb1397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import feature_extraction, linear_model, model_selection, preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9884944-e701-4556-a260-f239f3186d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words are the integral part of any classification technique. \n",
    "#However, these words are often used with different variations in the text depending on their grammar (verb, adjective, noun, etc.).\n",
    "#It is always a good practice to normalize the terms to their root forms.\n",
    "#This technique is known as Lemmatization.\n",
    "\n",
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a9d55ae-40f0-4cf1-8a05-0243ff9a28f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train.csv')\n",
    "prediction_frame = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dcb6642a-01aa-4854-8f6b-b11663cfeba4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f177eb50-e690-4598-b1af-7c0c5abb5a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20472cd2-66b3-45eb-b5e4-4fbdced3e37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id          7613\n",
       "keyword      221\n",
       "location    3341\n",
       "text        7503\n",
       "target         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# cardinality\n",
    "#\n",
    "train.apply(pd.Series.nunique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "34826586-b116-47b2-bab2-263e3df7b522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: Reported motor vehicle accident in Curry on Herman Rd near Stephenson involving an overturned vehicle. Please use... \n",
      "neg: What's up man?\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# show examples for positives and negatives in training data\n",
    "#\n",
    "print(\"pos:\", train[train[\"target\"] == 1][\"text\"].values[30])\n",
    "print(\"neg:\", train[train[\"target\"] == 0][\"text\"].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d751a0f5-dd98-4cf8-b2d2-93b8140628d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# clean text from urls\n",
    "#\n",
    "train['text'] = train['text'].apply(lambda x: re.split('http[s]?:\\/\\/.*', str(x))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e7d6e666-e347-411f-bcbb-f11bb623d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try different vectorization methods to improve model performance (TFIDF, LSA, LSTM / RNNs)\n",
    "\n",
    "#tfidf vectorizer (tatistical measure that evaluates how relevant a word is to a document in a collection of documents.)\n",
    "\n",
    "tfidf_vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer=LemmaTokenizer(), ngram_range=(1,1))\n",
    "\n",
    "\n",
    "## get counts for the first 5 tweets in the data\n",
    "example_train_vectors = tfidf_vectorizer.fit_transform(train[\"text\"][0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f772a975-a3c0-492b-a031-94c097fe5559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 57)\n",
      "[[0.         0.         0.         0.29167942 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.36152912 0.         0.         0.\n",
      "  0.         0.36152912 0.36152912 0.         0.         0.\n",
      "  0.         0.         0.         0.36152912 0.         0.36152912\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.36152912 0.         0.36152912\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(example_train_vectors.todense().shape)\n",
    "print(example_train_vectors[1].todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2ff26c7b-cfdf-4a7a-b08e-0fbea92fe458",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors = tfidf_vectorizer.fit_transform(train[\"text\"])\n",
    "prediction_frame_vectors = tfidf_vectorizer.transform(prediction_frame[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d6ad09-9567-40b5-8a6c-e38e96ec49a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "cdffcb8e-fa36-43e5-8ffa-d67bf167ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = linear_model.RidgeClassifier(alpha=0.8, class_weight=None, copy_X=True, fit_intercept=True,\n",
    "                max_iter=None, normalize=False, random_state=None,\n",
    "                solver='auto', tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "778f1aee-ff32-43db-951e-af5e35385638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6461039 , 0.60572012, 0.69129801])"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model_selection.cross_val_score(clf, train_vectors, train[\"target\"], cv=3, scoring=\"f1\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "004a49be-e347-4e5f-83d9-d86b1c298be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(train_vectors, train[\"target\"])\n",
    "sample_submission = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "sample_submission[\"target\"] = clf.predict(prediction_frame_vectors)\n",
    "sample_submission.to_csv(\"./data/output_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b28903-aa89-4c26-a398-3ed09d6261f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best output yet\n",
    "#array([0.65610143, 0.60869565, 0.69466403])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
